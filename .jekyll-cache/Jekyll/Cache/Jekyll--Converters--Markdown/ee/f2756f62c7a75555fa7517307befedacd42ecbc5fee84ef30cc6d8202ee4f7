I"Æ	<p>In my last <a href="/posts/tensorflow-with-big-tabular-datasets/">post</a> I talked about how I used TensorFlow datasets to speed up the training phase. Today I‚Äôve discovered another game changer: the <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch"><code class="language-plaintext highlighter-rouge">prefetch</code></a> method.</p>

<p>Whith this method, your dataset is going to prefetch (aka prepare before needed) some batches while the current element is being processed. Therefore, we improve latency and throughput at the cost of consuming more memory. Also, according to TensorFlow documentation:</p>

<blockquote>
  <p>Most dataset input pipelines should end with a call to prefetch</p>
</blockquote>

<p>To call the <code class="language-plaintext highlighter-rouge">prefetch</code> method you need to specify the <code class="language-plaintext highlighter-rouge">buffer_size</code>, this is the maximum number of elements that will be buffered when prefetching. If you want to set this value dinamycally to the ‚Äúoptimal‚Äù one <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> you can just use <code class="language-plaintext highlighter-rouge">tf.data.experimental.AUTOTUNE</code>.</p>

<p>Finally, just by adding the line</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><!-- <td class="rouge-gutter gl"><pre class="lineno">1
</pre></td> --><td class="rouge-code"><pre><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">AUTOTUNE</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>I‚Äôve reduced by 2 the training time of my model.</p>

<hr />

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>I didn‚Äôt find any TensorFlow documentation regarding how the optimal value is computed. I‚Äôll research this and write a post about it in the future.¬†<a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>
:ET